import streamlit as st
import pandas as pd
import requests
from io import BytesIO

# ğŸ”§ Page configuration
st.set_page_config(page_title="Sales Dashboard", layout="wide")

# ğŸ·ï¸ Title
st.title("ğŸ“Š Sales Data Analysis Dashboard")

# ğŸ“¥ Load and clean data
@st.cache_data
def load_data():
    url = "https://github.com/paulom40/PFonseca.py/raw/main/1semestrePM.xlsx"
    response = requests.get(url)
    if response.status_code != 200:
        st.error("âŒ Failed to load data from URL")
        return pd.DataFrame()

    df = pd.read_excel(BytesIO(response.content))

    # ğŸ§¼ Clean column names
    df.columns = df.columns.str.strip()

    # ğŸ“… Convert 'Date' to datetime
    if "Date" in df.columns:
        # Debugging: Show first few raw Date values
        st.write("First few raw Date values:", df["Date"].head().tolist())
        # Convert to numeric, coerce invalid values to NaN
        df["Date"] = pd.to_numeric(df["Date"], errors="coerce")
        # Debugging: Show first few numeric Date values
        st.write("First few numeric Date values:", df["Date"].head().tolist())
        # Convert to datetime, handling NaN explicitly
        df["Date"] = df["Date"].apply(
            lambda x: pd.NaT if pd.isna(x) else pd.to_datetime("1899-12-30") + pd.Timedelta(days=x)
        )
        # Debugging: Show first few converted Date values
        st.write("First few converted Date values:", df["Date"].head().tolist())
        # Extract week number, handle NaT values
        df["Week"] = df["Date"].dt.isocalendar().week.where(df["Date"].notna(), pd.NA)
        # Debugging: Show count of valid week values
        st.write(f"Valid 'Week' values after creation: {df['Week'].notna().sum()}")
    else:
        st.warning("âš ï¸ 'Date' column not found in dataset. 'Week' column will not be created.")
        df["Week"] = pd.NA

    # ğŸ”¢ Convert numeric columns
    for col in ["Quantidade", "PM", "Valor liquido"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        else:
            st.warning(f"âš ï¸ Column '{col}' not found in dataset.")

    # ğŸ§¹ Drop rows missing key fields
    df = df.dropna(subset=["Quantidade", "PM", "MÃªs", "Ano", "Artigo"])

    # Debugging: Show column names
    st.write("Loaded DataFrame columns:", df.columns.tolist())

    return df

# ğŸ“Š Load data
df = load_data()

# ğŸ›ï¸ Sidebar filters
st.sidebar.header("ğŸ›ï¸ Filtros")
selected_anos = st.sidebar.multiselect("Ano", sorted(df["Ano"].unique()), default=sorted(df["Ano"].unique()))
selected_meses = st.sidebar.multiselect("MÃªs", sorted(df["MÃªs"].unique()), default=sorted(df["MÃªs"].unique()))
selected_artigos = st.sidebar.multiselect("Artigo", sorted(df["Artigo"].unique()), default=sorted(df["Artigo"].unique()))

# ğŸ” Apply filters
filtered_df = df[
    df["Ano"].isin(selected_anos) &
    df["MÃªs"].isin(selected_meses) &
    df["Artigo"].isin(selected_artigos)
]

# Debugging: Show count of valid week values after filtering
st.write(f"Valid 'Week' values in filtered_df: {filtered_df['Week'].notna().sum()}")

# ğŸ“ˆ KPIs
st.header("ğŸ“ˆ Key Performance Indicators")
col1, col2, col3 = st.columns(3)

avg_pm = filtered_df["PM"].mean()
avg_qty_month = filtered_df.groupby("MÃªs")["Quantidade"].mean().mean()
avg_vliquido_by_month = filtered_df.groupby("MÃªs")["Valor liquido"].mean().mean()

col1.metric("Average PM", f"{avg_pm:.2f}")
col2.metric("Average Quantidade by Month", f"{avg_qty_month:.2f}")
col3.metric("Average Valor Liquido by Month", f"{avg_vliquido_by_month:.2f}")

# ğŸ“¦ Quantidade por MÃªs
st.subheader("ğŸ“¦ Quantidade por MÃªs")
st.bar_chart(filtered_df.groupby("MÃªs")["Quantidade"].sum())

# ğŸ’° Valor Liquido por MÃªs
st.subheader("ğŸ’° Valor Liquido por MÃªs")
st.line_chart(filtered_df.groupby("MÃªs")["Valor liquido"].mean())

# ğŸ“‹ Dados Filtrados
st.subheader("ğŸ“‹ Dados Filtrados")
st.dataframe(filtered_df, use_container_width=True)
